\section{Buffering Strategies for Large Matrices}
\label{sec:strategies}


Whenever the matrices are too large for all the allocations to fit on GPU, then they are split into blocks.
The algorithm can choose two values:
\begin{itemize}
	\item \code{num\_split\_common\_dim}, the number of splits for A's rows and B's columns. When splitting in this direction, a single value of C will be the sum of this amount of products among blocks of A and B.
	\item\code{num\_split\_other\_dim}, the number of splits for A's columns and B's rows. This will result in C being made of a square grid of blocks, with this value as edge. The different blocks will be independent from each other.
\end{itemize}

An example of matrix splitting is provided in figure~\ref{img:example-of-splits}.

\img{example-of-splits}{.6\linewidth}{An example of how matrices A and B can be split}

\subsection{Strategy 1: no buffering}



\subsection{Strategy 2: double buffer for A and B}
\subsection{Strategy 3: double buffer for A, B and C}
\subsection{Strategy 4: double concurrent product}


\subsection{Strassen algorithm}

We initially discussed about adding an option to use Strassen algorithm at this higher level.
Ideally it could be applied with any of the strategies described above.
The problem of this algorithm is that it requires 7 temporary matrices, for which we saw two options: storing all them in GPU memory, or loading and unloading them at need.

In order to compare the two options among them and with the traditional algorithm, we considered the case described in figure~\ref{img:matmul-2x2-normal}, where A and B do not fit on GPU memory, but they fit if they are divided in 4 blocks.

\img{matmul-2x2-normal}{.5\linewidth}{A product of 2x2 matrices with the traditional algorithm}
When using Strassen algorithm, the product would be as described in figure~\ref{img:matmul-2x2-strassen}

As visible in figure~\ref{img:matmul-flow-normal}, the traditional algorithm requires 20 memory transfers, to load the blocks of A and B, and to offload C when computed.
This example assumes that the GPU is divided into 3 blocks of equal size (the 3 squares on top of each other, in the image)
\img{matmul-flow-normal}{\linewidth}{The series of load/calc/unload operations for a 2x2 product with the traditional algorithm}
If we want to use Strassen algorithm with blocks of the same size, figure~\ref{img:matmul-flow-strassen-more-transfers} reveals that 45 memory transfers are required, because the program needs to offload temporary sums and matrices to make space for the other values.
\img{matmul-flow-strassen-more-transfers}{\linewidth}{The series of load/calc/unload operations for a 2x2 product with Strassen algorithm, if we want to have the GPU memory divided in just 3 blocks}
If instead we decide to have more blocks for the Strassen algorithm, in order to avoid offloading temporary results, we would need 21 memory transfers, as shown in figure~\ref{img:matmul-flow-strassen-more-memory}.
This removes one multiplication with respect to the traditional algorithm, at the cost of adding just an extra memory transfer.
In principle it would be good, if not for the fact that this approach requires the blocks to have half the size, thus having on average $\sqrt{2}$ more blocks, that need more multiplications that the ones saved by the Strassen algorithm.
\img{matmul-flow-strassen-more-memory}{\linewidth}{The series of load/calc/unload operations for a 2x2 product with Strassen algorithm, if we want to avoid offloading temporary results}

As a conclusion, we realized that Strassen algorithm was an efficient way to save computation time, but only if the full matrices were fully available on GPU, thus making memory transfers not needed.
