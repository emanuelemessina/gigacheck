\section{Block Product, Error Detection and Correction}
\label{sec:block}

\subsection{Computing checksums}

The checksums are computed by a single kernel, that based on a parameter computes row or column checksums.

For row checksums, a thread block is generated for each row, with a set of threads that initially sum a portion of the row, in a linear way.
After that, the different threads of the block organize themselves to sum all the partial sums in a dichotomous way.

Similarly, column checksums generate a thread block for each column, performing the same operations in the opposite direction.

After the computation, the kernel is able to store the checksum either in the last row or column of the matrix, or into a separate vector, in order to avoid overriding the previous checksums (the control checksums of C).

\img{checksums-pseudocode}{0.7\linewidth}{the pseudocode of the kernel that computes the checksums}

\subsection{Computing the product}

When the matrices are small enough to fit on GPU (or we are working on blocks), the multiplication is realized by means of the standard tiled algorithm for GPU.

Initially, we believed that we could apply one or two recursions of Strassen algorithm to reduce the number of products.
Then, we realized that this would make the same error appear in different submatrices: this would make it much harder to correct it, since non-collinear errors are not correctable.
For this reason, we decided to drop Strassen algorithm at this smaller size level.

\img{tiled-matmul-pseudocode}{0.7\linewidth}{the pseudocode of the kernel that computes the matrix multiplication using the tiled approach}

\subsection{Error correction}
