\section{Background Theory}
\label{sec:background}

\subsection{ABFT matrix multiplication}

The basic idea behind Algorithm-Based Fault Tolerant (ABFT) matrix multiplication
is to use checksums to verify the correctness of the computation.
These are the steps we perform:

\begin{enumerate}
  \item \textbf{Checksum Calculation}:
    Let \( A \) be an \( m \times n \) matrix,
    \( B \) be an \( n \times q \) matrix,
    and \( C \) be the resulting \( m \times q \) matrix
    from the multiplication \( C = A B \).
    Before performing the matrix multiplication,
    we calculate the column checksum of \( A \) and the row checksum of \( B \):

    \[
      \textnormal{Column checksum of } A: \quad
      \mathbf{c}_A =
      \left[
        \sum_{i=1}^{n} a_{i1},
        \sum_{i=1}^{n} a_{i2},
        \ldots, \sum_{i=1}^{n} a_{in}
      \right]
    \]

    \[
      \textnormal{Row checksum of } B: \quad
      \mathbf{r}_B = \left[ \sum_{j=1}^{n} b_{1j}, \sum_{j=1}^{n} b_{2j}, \ldots, \sum_{j=1}^{n} b_{nj} \right]
    \]

    \textit{
      The row checksum of a matrix is a column vector where each element
      is the sum of the elements in the corresponding row of the matrix.
      Similarly, the column checksum is a row vector where
    each element is the sum of the elements in the corresponding column of the matrix.}

  \item \textbf{Augmented Matrices}:
    We then create augmented matrices $A_{c}$ (\( m+1 \times n \)) and $B_{r}$ (\( n \times q+1 \))
    by appending the column and row checksum vectors, respectively, to the original matrices:
    Thus we get:
    \[
      A_{c} =
      \left[
        \begin{array}{c}
          A \\
          \midrule
          \mathbf{c}_A
        \end{array}
      \right]
      \quad
      ,
      \quad
      B_{r} = \left[
        \begin{array}{c|c}
          B &
          \mathbf{r}_B
        \end{array}
      \right]
    \]
  \item \textbf{Multiplication}: We multiply $ A_{c} $ and $ B_{r} $ together, yielding
    \[
      C_{cr} = A_{c} B_{r} = \left[
        \begin{array}{c|c}
          A B & A \, \mathbf{r}_B \\
          \hline
          \mathbf{c}_A \, B & \mathbf{c}_A \, \mathbf{r}_B
        \end{array}
      \right]
    \]
    We see that the original product is preserved
    in the upper left block,
    while the other blocks contain checksum information.

  \item \textbf{Checksum Verification}:
    Considering the column and row checksums of the upper left block of
    the resulting matrix \( C_{cr} \), the following properties hold:

    \[
      \mathbf{c}_{AB} = \left[\mathbf{c}_A \, B \right]
      \quad
      ,
      \quad
      \mathbf{r}_{AB} = \left[A \, \mathbf{r}_B \right]
    \]

    The proof is trivial.

    This is the property that we ultimately exploit to correct errors in the computation,
    because if the upper block returned to us is corrupted,
    then we can compute its checksums (we will call them control checksums)
    and compare them against the peripheral blocks to at least detect the corruption of the result.

    In general, the column checksum of the upper blocks of the augmented result
    is equal to the last row of the aumented result, and the row cheksum of the left blocks of the augmented result
    is equal to the last column the augmented result. In formulas:

    \[
      \mathbf{c}_{\text{control}} = \mathbf{c}_{
        \begin{array}{c|c}
          A B & A \, \mathbf{r}_B
        \end{array}
      } =
      \left[
        \begin{array}{c|c}
          \mathbf{c}_A \, B &
          \mathbf{c}_A \, \mathbf{r}_B
        \end{array}
      \right]
    \]

    \[
      \mathbf{r}_{\text{control}} = \mathbf{r}_{
        \begin{array}{c}
          AB \\
          \midrule
          \mathbf{c}_A \, B
      \end{array}} =
      \left[
        \begin{array}{c}
          A \, \mathbf{r}_B \\
          \hline
          \mathbf{c}_A \, \mathbf{r}_B
        \end{array}
      \right]
    \]

    As we can see, the last element of each control checksum, is the same,
    and also corresponds exactly to $C_{cr}\left[m+1,q+1\right]$.
    This element is the one that allows us to detect errors
    in the checksum blocks themselves, generalizing the approach to the entire
    augmented result matrix and not just the upper left block containing the original product.

    Wherever there is a mismatch between the returned checksum blocks and the associated computed control checksum,
    we know: first, that there is an error in $C_{cr}$; and second, one coordinate of the error.

    In the case of a single error inside $C_{cr}$,
    there would be a single mismatch in both
    $\mathbf{r}_{\text{control}}$ and $\mathbf{c}_{\text{control}}$.
    The item indexes on the control checksum vectors
    give the coordinates of the error inside the result matrix.

    If there are multiple errors, they can be collinear or not.
    By collinear errors we mean errors that share one coordinate,
    or equivalently stated,
    they are arranged on the same column or row in the result matrix.
    Collinear errors can be individually detected and isolated.

    The presence of at least two non collinear errors
    can only be detected, but the exact coordinates of the individual errors
    cannot be obtained.

    \img{correctable}{.5\linewidth}{Detectable errors cause exactly one mismatch in at least one of the control checksums.}

    \img{uncorrectable}{.5\linewidth}{An error set that cause more than one mismatch in both checksums does not allow us to recover the individual error placement inside the matrix, since the configuration is ambiguous.}

    \img{checkerr}{.5\linewidth}{Errors in the checksum blocks themselves cause a mismatch in the shared item (the last item), and so can be detected as any other detectable error.}

  \item \textbf{Error Correction}:

    TODO SPIEGAZIONE + FORMULA ERROR CORRECTION

\end{enumerate}

\subsection{Strassen}

TODO spiegare Strassen
